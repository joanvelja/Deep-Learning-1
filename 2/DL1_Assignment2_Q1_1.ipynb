{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox90Qf6N1dvr"
      },
      "source": [
        "# DL1 Assignment2 - Q1.1 draft code\n",
        "\n",
        "This is a small help from us to save you some coding. This notebook is **not** graded, you are free to edit it.\n",
        "\n",
        "Further advise:\n",
        "1. Start with File/Save a copy in Drive\n",
        "2. Set GPU usage under Runtime/Change runtime type/Hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8iuexbuX1A",
        "outputId": "44a3dedd-328a-4238-f36f-c7b70ce293b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.11-py3-none-any.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from timm) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from timm) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (4.8.0)\n",
            "Requirement already satisfied: sympy in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torch>=1.7->timm) (2023.10.0)\n",
            "Requirement already satisfied: requests in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torchvision->timm) (1.26.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from torchvision->timm) (10.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/joanvelja/anaconda3/envs/dl2023/lib/python3.11/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Downloading timm-0.9.11-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.4/425.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.19.4 safetensors-0.4.0 timm-0.9.11\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D1viWETquNc6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import timm\n",
        "from torchvision import models\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Callable\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5wwMtxyDumgb"
      },
      "outputs": [],
      "source": [
        "def vit_s_8():\n",
        "    \"\"\"ViT-S/8 is not a default torchvision model, so we provide it by timm\"\"\"\n",
        "    # Accuracy approximation comes from\n",
        "    # https://openreview.net/pdf?id=LtKcMgGOeLt\n",
        "    # and DINO\n",
        "    # https://arxiv.org/abs/2104.14294\n",
        "    return timm.create_model('vit_small_patch8_224')\n",
        "\n",
        "def drop_outliers(data):\n",
        "    Q1 = np.percentile(data, 25)\n",
        "    Q3 = np.percentile(data, 75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define outlier cutoff\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Filter out outliers\n",
        "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "    # Calculate the mean\n",
        "    mean_value = np.mean(filtered_data)\n",
        "\n",
        "    return mean_value\n",
        "\n",
        "# Model definitions\n",
        "# Optional Q: These are uncalled functions. What do you think would happen\n",
        "# if we called all of them once? Why didn't we do that?\n",
        "model_defs = [\n",
        "    vit_s_8,\n",
        "    models.vit_b_32,\n",
        "    models.vgg11,\n",
        "    models.vgg11_bn,\n",
        "    models.resnet18,\n",
        "    models.densenet121,\n",
        "    models.mobilenet_v3_small,\n",
        "]\n",
        "\n",
        "# Accuracies per model\n",
        "model_accs = {\n",
        "    'vit_s_8': 80., # Approximated\n",
        "    'vit_b_32' : 75.912,\n",
        "    'vgg11' : 69.02,\n",
        "    'vgg11_bn' : 70.37,\n",
        "    'resnet18' : 69.758,\n",
        "    'densenet121' : 74.434,\n",
        "    'mobilenet_v3_small' : 67.668,\n",
        "}\n",
        "\n",
        "\n",
        "def measure_runtime_per_forward(model:nn.Module, no_grad:bool, batch_size:int=8):\n",
        "    \"\"\"Measures the time for a single pass in milliseconds\"\"\"\n",
        "\n",
        "    # Generate fake RGB input (224x224)\n",
        "    x = torch.rand((batch_size,3,224,224))\n",
        "\n",
        "    #try:   \n",
        "        #start = torch.cuda.Event(enable_timing=True)\n",
        "        #end = torch.cuda.Event(enable_timing=True)\n",
        "        #x = x.to('cuda')\n",
        "    #except:\n",
        "\n",
        "    start = torch.mps.Event(enable_timing=True)\n",
        "    end = torch.mps.Event(enable_timing=True)\n",
        "    x = x.to('mps')\n",
        "    \n",
        "    start.record()\n",
        "\n",
        "    # Run the model\n",
        "    #weights = 'DEFAULT'\n",
        "    #model = model(weights=weights)\n",
        "    model.eval()\n",
        "    \n",
        "    if no_grad:\n",
        "        model.zero_grad()\n",
        "    \n",
        "    prediction = model(x)\n",
        "    #class_id = prediction.argmax().item()\n",
        "    #score = prediction[class_id].item()\n",
        "    #category_name = weights.meta[\"categories\"][class_id]\n",
        "    #print(f\"{category_name}: {100 * score:.1f}%\")\n",
        "\n",
        "    end.record()\n",
        "    #try:\n",
        "        #torch.cuda.synchronize()\n",
        "    #except:\n",
        "    torch.mps.synchronize()\n",
        "        \n",
        "    return start.elapsed_time(end)\n",
        "\n",
        "\n",
        "def evaluate_model(model_def:Callable, no_grad:bool, batch_size:int=8):\n",
        "\n",
        "    # Retreive initial memory allocation\n",
        "    #try:\n",
        "        #initial_vram = torch.cuda.memory_allocated()\n",
        "    #except:\n",
        "    initial_vram = torch.mps.current_allocated_memory()\n",
        "    print(f\"Initial mem: {torch.mps.driver_allocated_memory()}\")\n",
        "    initial_vram2 = torch.mps.driver_allocated_memory()\n",
        "\n",
        "\n",
        "    # Define model\n",
        "    #try:\n",
        "        #model = model_def().cuda().eval()\n",
        "    #except:\n",
        "    model = model_def().eval().to('mps')\n",
        "\n",
        "    # Access name as: model.__name__\n",
        "\n",
        "    # Parameters that need to be filled\n",
        "    times, vrams = [], []\n",
        "    mean_time = None\n",
        "    mean_vram = None\n",
        "\n",
        "\n",
        "\n",
        "    #######################\n",
        "    # PUT YOUR CODE HERE  #\n",
        "    #######################\n",
        "\n",
        "    # Step 1: Calculate the number of **trainable** parameters\n",
        "\n",
        "    train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    # Step 2: Warm up with a few passes\n",
        "\n",
        "    measure_runtime_per_forward(model, no_grad, batch_size)\n",
        "    measure_runtime_per_forward(model, no_grad, batch_size)\n",
        "    measure_runtime_per_forward(model, no_grad, batch_size)\n",
        "    measure_runtime_per_forward(model, no_grad, batch_size)    \n",
        "\n",
        "    # Step 3: Run N forward passes and save the runtime +\n",
        "    #         the vram allocated by the model\n",
        "\n",
        "    N = 10\n",
        "    args = {'model': model, 'no_grad': no_grad, 'batch_size': batch_size}\n",
        "\n",
        "    for _ in range (N):\n",
        "        time = measure_runtime_per_forward(**args)\n",
        "        times.append(time)\n",
        "        #try:\n",
        "            #allocated_vram = torch.cuda.memory_allocated() - initial_vram\n",
        "        #except:\n",
        "        allocated_vram = torch.mps.current_allocated_memory() - initial_vram\n",
        "        print(f\"{torch.mps.driver_allocated_memory() - initial_vram2}\")\n",
        "    \n",
        "        vrams.append(allocated_vram)\n",
        "\n",
        "    # Step 4: Take the mean, preferably with dropping possible outliers\n",
        "    for \n",
        "        Q1 = np.percentile(data, 25)\n",
        "        Q3 = np.percentile(data, 75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Define outlier cutoff\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Filter out outliers\n",
        "        filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "        # Calculate the mean\n",
        "        mean_value = np.mean(filtered_data)\n",
        "        \n",
        "    mean_time = np.mean(time)\n",
        "    mean_vram = np.mean(vrams)\n",
        "\n",
        "    # Clean up space for the model\n",
        "    del model\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except:\n",
        "        torch.mps.empty_cache()\n",
        "\n",
        "    return mean_time, mean_vram, train_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7iUTuJH7uQqs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial mem: 11460739072\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "169869312\n",
            "vit_s_8 173.342209 86681088.0 21670272\n",
            "Initial mem: 11630608384\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "-37748736\n",
            "vit_b_32 35.418749999999996 389839360.0 88224232\n",
            "Initial mem: 11592859648\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "85983232\n",
            "vgg11 31.240707999999998 544855040.0 132863336\n",
            "Initial mem: 11678842880\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "-12582912\n",
            "vgg11_bn 34.855790999999996 544902400.0 132868840\n",
            "Initial mem: 11666259968\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "60817408\n",
            "resnet18 11.099375 47971072.0 11689512\n",
            "Initial mem: 11727077376\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "-205520896\n",
            "densenet121 54.0075 35158016.0 7978856\n",
            "Initial mem: 11521556480\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "mobilenet_v3_small 15.969916999999999 12204288.0 2542856\n"
          ]
        }
      ],
      "source": [
        "#######################\n",
        "# PUT YOUR CODE HERE  #\n",
        "#######################\n",
        "\n",
        "# Make your plots here with matplotlib\n",
        "#\n",
        "# Example usage of the above functions:\n",
        "for model_def in model_defs:\n",
        "    name = model_def.__name__\n",
        "    time, vram, n_params = evaluate_model(model_def, no_grad=True)\n",
        "    print(name, time, vram, n_params)\n",
        "\n",
        "#######################\n",
        "# END OF YOUR CODE    #\n",
        "#######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-Kr15X93urVC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model mobilenet_v3_small achieves runtime of 82.28845799999999\n"
          ]
        }
      ],
      "source": [
        "\n",
        "time = measure_runtime_per_forward(models.resnet18().to('mps'), no_grad=True)\n",
        "print(f\"Model {name} achieves runtime of {time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
